{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c5ea68",
   "metadata": {},
   "source": [
    "# 0. Load required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd8d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pickle\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ad523",
   "metadata": {},
   "source": [
    "# 1. Load the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe7e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_pos.pickle', 'rb') as f:\n",
    "    data_pos = pickle.load(f)\n",
    "with open('./data_set1.pickle', 'rb') as f:\n",
    "    data_set1 = pickle.load(f)    \n",
    "with open('./data_set2.pickle', 'rb') as f:\n",
    "    data_set2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a6025",
   "metadata": {},
   "source": [
    "# 2. Load the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cdc351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '/home/skhong/WordImportance/bert_tf/qnli/pytorch_model.bin'\n",
    "config_file = '/home/skhong/WordImportance/bert_tf/qnli/config.json'\n",
    "vocab_file = '/home/skhong/WordImportance/bert/qnli/vocab.txt'\n",
    "model_version = 'bert-base-uncased'\n",
    "config = BertConfig.from_json_file(config_file)\n",
    "model = BertForSequenceClassification(config)\n",
    "state_dict = torch.load(model_file)\n",
    "model.load_state_dict(state_dict)\n",
    "tokenizer = BertTokenizer(vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d51146",
   "metadata": {},
   "source": [
    "# 3. Extract attention values between tokens.\n",
    "- For models with WI added, perform the addition and extract attention values; for cases where it's not the case, input the excluded ones and extract attention values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384817c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29678/1953570433.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, data in tqdm_notebook(enumerate(data_pos), total=len(data_pos)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a44c3a9ef64eb1a75507ca1e8d18cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, data in tqdm_notebook(enumerate(data_pos), total=len(data_pos)):\n",
    "    input_ids = data[0]\n",
    "    token_type_ids = data[1]\n",
    "    tfidf_ids = data[2]\n",
    "    \n",
    "    i_pos = data_set1[i][0]\n",
    "    j_pos = data_set1[i][1]\n",
    "    j_random_pos = data_set2[i][1]\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            pred = model(input_ids, token_type_ids=token_type_ids, tfidf_ids=tfidf_ids)\n",
    "    except:\n",
    "        print(input_ids.shape)\n",
    "    temp_x1 = []\n",
    "    temp_x2 = []\n",
    "    \n",
    "    # 128 is the maximum input length for the model's text.\n",
    "    for k in range(12):\n",
    "        temp_data = pred.attentions[k].detach().cpu().numpy().reshape(12, 512, 512)\n",
    "        \n",
    "        for l in range(12):\n",
    "            temp_x1.append(temp_data[l][i_pos][j_pos])\n",
    "            temp_x2.append(temp_data[l][i_pos][j_random_pos])\n",
    "    \n",
    "    Y.append(1)\n",
    "    X.append(temp_x1)\n",
    "    Y.append(0)\n",
    "    X.append(temp_x2)\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfbfb1c5-3ed4-4170-9d0c-f1c197fb8ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987d6d4",
   "metadata": {},
   "source": [
    "# 4. WI Validation Model based Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9430f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC :  0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y, random_state=34)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "clf = RandomForestClassifier(\n",
    "            n_estimators=50, \n",
    "            criterion='entropy', \n",
    "            max_depth=5, \n",
    "            max_features='sqrt',\n",
    "            max_samples=0.9,\n",
    "            bootstrap=True,\n",
    "            oob_score=True, \n",
    "            random_state=100\n",
    "        ).fit(x_train,y_train)\n",
    "\n",
    "## Performance Evaluation\n",
    "print('ACC : ', clf.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65a39b-f05a-42fe-87c5-3eba5bc54bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
